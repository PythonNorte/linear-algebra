
\begin{enumerate}

\item Explain the dot product and inner product. Use them to define length and angles of vectors. Normalize vectors, obtain vectors of a given length in a given direction, and explain how to tell if two vectors are orthogonal. 

\item Explain how the inner product can be generalized to vector spaces other than $\RR^n$, and give examples of computing angles and lengths of vectors using an inner product over a vector space other than $\RR^n$.

\item Obtain the orthogonal complement of a set of vectors (relate it to the null space of the transpose). Use the orthogonal complement to project vectors onto vector spaces. 

\item By considering the projection of a vector onto a vector subspace, explain why solving $A^TA \vec x = A^T\vec b$ gives the solution to the least squares regression problem.

\item Use the Gram-Schmidt orthogonalization process to obtain an orthonormal basis of vectors. Show how to compute coordinates of vectors relative to an orthogonal basis.

%\item Illustrate by examples that when a matrix is symmetric, eigenvectors corresponding to different eigenvalues are orthogonal, which means you can find an orthonormal basis to diagonalize the matrix. 

\end{enumerate}
